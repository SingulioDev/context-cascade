

## When to Use This Skill

- **Tool Usage**: When you need to execute specific tools, lookup reference materials, or run automation pipelines
- **Reference Lookup**: When you need to access documented patterns, best practices, or technical specifications
- **Automation Needs**: When you need to run standardized workflows or pipeline processes

## When NOT to Use This Skill

- **Manual Processes**: Avoid when manual intervention is more appropriate than automated tools
- **Non-Standard Tools**: Do not use when tools are deprecated, unsupported, or outside standard toolkit

## Success Criteria

- **Tool Executed Correctly**: Verify tool runs without errors and produces expected output
- **Reference Accurate**: Confirm reference material is current and applicable
- **Pipeline Complete**: Ensure automation pipeline completes all stages successfully

## Edge Cases

- **Tool Unavailable**: Handle scenarios where required tool is not installed or accessible
- **Outdated References**: Detect when reference material is obsolete or superseded
- **Pipeline Failures**: Recover gracefully from mid-pipeline failures with clear error messages

## Guardrails

- **NEVER use deprecated tools**: Always verify tool versions and support status before execution
- **ALWAYS verify outputs**: Validate tool outputs match expected format and content
- **ALWAYS check health**: Run tool health checks before critical operations

## Evidence-Based Validation

- **Tool Health Checks**: Execute diagnostic commands to verify tool functionality before use
- **Output Validation**: Compare actual outputs against expected schemas or patterns
- **Pipeline Monitoring**: Track pipeline execution metrics and success rates

# Skill Enhancement Pipeline Automation
You are following structured enhancement instructions. Execute tasks sequentially with explicit validation gates. Document all modifications with clear rationale. Preserve existing functionality while implementing improvements. Use MECE principles for systematic coverage.
You are following structured enhancement instructions. Execute tasks sequentially with explicit validation gates. Document all modifications with clear rationale. Preserve existing functionality while implementing improvements. Use MECE principles for systematic coverage.

**Purpose**: Systematically enhance all 256 skills to MECE universal template standards

## Architecture

### Phase 0: Preparation ✅ COMPLETE
- Research existing skills
- Identify meta skills
- Create MECE gap analysis
- Build automation scripts

### Phase 1: Meta Skills Enhancement (IN PROGRESS)
- Enhance 13 meta skills to Gold tier
- Test meta skills on samples
- Validate audit pipeline

### Phase 2: Pilot Testing
- Enhance 10 sample skills
- Run full pipeline with audits
- Measure velocity and quality

### Phase 3: Batch Enhancement
- Process all 256 skills in batches of 10
- Bronze tier for all (3 files minimum)
- Silver tier for high-impact (7+ files)
- Gold tier for critical (12+ files)

## Scripts

### 1. `generate-mece-chart.py`
**Purpose**: Analyze all skills and generate gap analysis

**Usage**:
```bash
# Basic analysis
python generate-mece-chart.py ../

# JSON output
python generate-mece-chart.py ../ --json

# Detailed per-skill report
python generate-mece-chart.py ../ --json --detailed > gap-analysis.json
```

**Output**:
- Total skills analyzed
- Meta skills identified
- Tier distribution
- Missing components count
- Completion percentages
- Enhancement requirements

### 2. `enhance-skill.py`
**Purpose**: Generate enhancement plan for a single skill

**Usage**:
```bash
# Enhance to Bronze tier (default)
python enhance-skill.py ../skill-name

# Enhance to specific tier
python enhance-skill.py ../skill-name --tier Gold

# Generate plan only (no execution)
python enhance-skill.py ../functionality-audit --tier Gold
```

**Output**:
- `enhancements/{skill-name}-plan.json` - Enhancement plan
- `enhancements/{skill-name}-instructions.md` - Agent instructions

**Features**:
- Analyzes current skill state
- Calculates missing components for target tier
- Generates task breakdown by agent
- Creates coordination protocol instructions
- Estimates time requirements

### 3. `audit-skill.py`
**Purpose**: Validate skill against MECE universal template

**Usage**:
```bash
# Full audit with summary
python audit-skill.py ../skill-name

# JSON output only
python audit-skill.py ../skill-name --json
```

**Output**:
- `audits/{skill-name}-audit.json` - Audit report

**Audit Categories**:
1. **Structure** (40% weight):
   - skill.md exists
   - README.md exists
   - examples/ directory with ≥1 example
   - No root file violations
   - Proper directory naming
   - No orphaned files

2. **Content** (30% weight):
   - YAML frontmatter in skill.md
   - Imperative voice usage
   - README overview and quick start
   - Concrete examples (not abstract)
   - File naming conventions

3. **Quality Tier** (30% weight):
   - Bronze: 3+ files (skill.md, README.md, 1 example)
   - Silver: 7+ files (+ references/, graphviz/)
   - Gold: 12+ files (+ resources/, tests/)
   - Platinum: 20+ files (comprehensive)

**Decision Criteria**:
- Overall score ≥85% → GO (approved)
- Overall score <85% → NO-GO (needs improvement)

### 4. `batch-enhance.sh` (Coming Soon)
**Purpose**: Orchestrate batch enhancement of 10 skills

**Planned Features**:
- Read batch manifest (10 skills)
- Parallel enhancement using Claude Code Task tool
- Sequential audit validation
- Quality threshold enforcement
- Memory namespace tracking

## Memory Namespace

```
skill-enhancement-pipeline/
├── meta-skills/
│   ├── functionality-audit/
│   │   ├── status: "enhanced-to-Gold"
│   │   ├── enhancements: ["README.md", "examples/", "graphviz/", "resources/"]
│   │   └── audit-results: {"overall_score": 0.92, "decision": "GO"}
│   └── theater-detection-audit/
│       └── status: "pending"
├── batch-1/
│   ├── started: "2025-11-02T10:00:00Z"
│   ├── progress: "3/10"
│   ├── skills: ["skill-1", "skill-2", "skill-3"]
│   └── quality_score: 0.87
└── pipeline-config/
    ├── batch_size: 10
    ├── quality_threshold: 0.85
    └── parallel_agents: 4
```

## Workflow Example

### Enhance functionality-audit to Gold Tier

**Step 1: Generate Enhancement Plan**
```bash
cd skills/_pipeline-automation
python enhance-skill.py ../functionality-audit --tier Gold
```

Output:
```
[ANALYZE] Analyzing functionality-audit...
[RESULT] Current tier: Incomplete
[RESULT] Target tier: Gold
[RESULT] Missing components: README.md, examples/, references/, graphviz/, resources/scripts/

[PLAN] Creating enhancement plan for Gold tier...
[RESULT] Enhancement tasks: 5
[RESULT] Estimated time: 3.5 hours

[SAVE] Plan saved to enhancements/functionality-audit-plan.json
[SAVE] Instructions saved to enhancements/functionality-audit-instructions.md
```

**Step 2: Execute Enhancement (Using Claude Code)**
```javascript
// In Claude Code conversation
Task("technical-writer", `
  Read: enhancements/functionality-audit-instructions.md
  Create README.md and references/ for functionality-audit skill
  Follow MECE universal template standards
`, "technical-writer")

Task("researcher", `
  Read: enhancements/functionality-audit-instructions.md
  Create 3 concrete examples for functionality-audit skill
  Examples: basic, agent-powered, edge-case
`, "researcher")

Task("architect", `
  Read: enhancements/functionality-audit-instructions.md
  Create GraphViz workflow diagram for functionality-audit
`, "architect")

Task("coder", `
  Read: enhancements/functionality-audit-instructions.md
  Create Python validation scripts in resources/scripts/
`, "coder")
```

**Step 3: Audit Enhanced Skill**
```bash
python audit-skill.py ../functionality-audit
```

Output:
```
[AUDIT] Structural validation...
[AUDIT] Content validation...
[AUDIT] Quality tier validation...

================================================================================
AUDIT REPORT: functionality-audit
================================================================================

[RESULT] Overall Score: 92.0%
[RESULT] Quality Tier: Gold
[RESULT] Decision: GO

[SCORES] Category Breakdown:
   Structure            95.0%
   Content              90.0%
   Quality Tier         85.0%

[CHECKS] Summary:
   Passed:   18 checks
   Failed:    2 checks

================================================================================
STATUS: APPROVED - Skill meets quality standards
================================================================================
```

**Step 4: Store Results in Memory**
```bash
npx claude-flow@alpha memory store \
  --key "skill-enhancement-pipeline/meta-skills/functionality-audit/status" \
  --value "enhanced-to-Gold"

npx claude-flow@alpha memory store \
  --key "skill-enhancement-pipeline/meta-skills/functionality-audit/audit-results" \
  --value '{"overall_score": 0.92, "decision": "GO", "tier": "Gold"}'
```

## Quality Gates

### Gate 1: Structural Compliance
- All required files present (skill.md, README.md, examples/)
- MECE directory structure
- No orphaned files
- **Threshold**: 100% required, 0% optional OK

### Gate 2: Content Quality
- YAML frontmatter valid
- Imperative voice in skill.md
- Concrete examples present
- README has overview + quick start
- **Threshold**: ≥80% content checks pass

### Gate 3: Overall Quality
- Combined score from all categories
- Tier achievement verified
- **Threshold**: ≥85% overall score for GO decision

## Meta Skills Priority Order

1. ✅ **skill-forge** (Gold tier) - Universal template
2. **functionality-audit** - Does it work? (sandbox testing)
3. **theater-detection-audit** - Real code validation
4. **verification-quality** - Quality standards validation
5. **style-audit** - Code style consistency
6. **agent-creator** - Agent creation methodology
7. **intent-analyzer** - Intent analysis for unclear requests
8. **skill-creator-agent** - Skill creation with agents
9. **micro-skill-creator** - Atomic skill creation
10. **cascade-orchestrator** - Multi-skill workflows
11. **quick-quality-check** - Fast parallel validation
12. **reproducibility-audit** - Reproducibility verification
13. **sop-dogfooding-quality-detection** - Quality detection SOP
14. **deep-research-orchestrator** - Research pipeline orchestration

## Timeline (7 Weeks)

- **Week 1**: Meta skills enhancement (13 skills × 3.5 hours = 46 hours with 4-agent parallelization)
- **Week 2**: Pilot testing (10 skills, validate pipeline)
- **Weeks 3-6**: Batch enhancement (246 remaining skills)
- **Week 7**: Final validation and deployment

## Success Metrics

### Quantitative
- 100% of skills have Bronze tier minimum (3 files)
- 50+ skills at Silver tier (7+ files)
- 20+ skills at Gold tier (12+ files)
- 5+ skills at Platinum tier (20+ files)
- Overall quality score ≥85%

### Qualitative
- Consistent structure across all skills
- Easy navigation and discoverability
- Production-ready documentation
- Validated by meta skills

### Validation
- All enhancements pass audit (≥85%)
- Meta skills validate each other (cross-validation)
- Pilot testing confirms velocity and quality
- User feedback positive on new structure
